{
  "test_run": {
    "timestamp": "2025-08-16T17:14:19.667469",
    "total_execution_time": 447.956081867218,
    "summary": {
      "total_suites": 6,
      "passed": 1,
      "failed": 5,
      "errors": 0,
      "success_rate": 16.666666666666664
    },
    "results": {
      "Business Analyst Agent": {
        "status": "PASSED",
        "execution_time": 1.8480174541473389,
        "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.4.1, pluggy-1.6.0 -- /workspaces/agentic-ecosystem/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.3', 'Platform': 'Linux-6.8.0-1030-azure-x86_64-with-glibc2.39', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'httpx': '0.35.0', 'asyncio': '1.1.0', 'anyio': '4.10.0', 'langsmith': '0.4.14', 'metadata': '3.1.1', 'json-report': '1.5.0', 'mock': '3.14.1'}, 'JAVA_HOME': '/usr/local/sdkman/candidates/java/current'}\nrootdir: /workspaces/agentic-ecosystem\nconfigfile: pytest.ini\nplugins: httpx-0.35.0, asyncio-1.1.0, anyio-4.10.0, langsmith-0.4.14, metadata-3.1.1, json-report-1.5.0, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 7 items\n\ntests/test_ba_agent.py::TestBusinessAnalystAgent::test_analyze_business_requirements_basic PASSED [ 14%]\ntests/test_ba_agent.py::TestBusinessAnalystAgent::test_analyze_business_requirements_file_output PASSED [ 28%]\ntests/test_ba_agent.py::TestBusinessAnalystAgent::test_analyze_business_requirements_empty_specification PASSED [ 42%]\ntests/test_ba_agent.py::TestBusinessAnalystAgent::test_analyze_business_requirements_error_handling PASSED [ 57%]\ntests/test_ba_agent.py::TestBusinessAnalystAgent::test_user_story_validation PASSED [ 71%]\ntests/test_ba_agent.py::TestBusinessAnalystAgent::test_requirements_categorization PASSED [ 85%]\ntests/test_ba_agent.py::TestBusinessAnalystAgent::test_priority_assignment PASSED [100%]\n\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_business_analyst_agent.json\n============================== 7 passed in 0.89s ===============================\n",
        "stderr": "",
        "return_code": 0
      },
      "Architect Agent": {
        "status": "FAILED",
        "execution_time": 1.8954553604125977,
        "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.4.1, pluggy-1.6.0 -- /workspaces/agentic-ecosystem/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.3', 'Platform': 'Linux-6.8.0-1030-azure-x86_64-with-glibc2.39', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'httpx': '0.35.0', 'asyncio': '1.1.0', 'anyio': '4.10.0', 'langsmith': '0.4.14', 'metadata': '3.1.1', 'json-report': '1.5.0', 'mock': '3.14.1'}, 'JAVA_HOME': '/usr/local/sdkman/candidates/java/current'}\nrootdir: /workspaces/agentic-ecosystem\nconfigfile: pytest.ini\nplugins: httpx-0.35.0, asyncio-1.1.0, anyio-4.10.0, langsmith-0.4.14, metadata-3.1.1, json-report-1.5.0, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 8 items\n\ntests/test_architect_agent.py::TestArchitectAgent::test_design_system_architecture_basic FAILED [ 12%]\ntests/test_architect_agent.py::TestArchitectAgent::test_architecture_component_types FAILED [ 25%]\ntests/test_architect_agent.py::TestArchitectAgent::test_technology_stack_consistency FAILED [ 37%]\ntests/test_architect_agent.py::TestArchitectAgent::test_security_considerations_coverage FAILED [ 50%]\ntests/test_architect_agent.py::TestArchitectAgent::test_data_flow_completeness FAILED [ 62%]\ntests/test_architect_agent.py::TestArchitectAgent::test_architecture_file_output PASSED [ 75%]\ntests/test_architect_agent.py::TestArchitectAgent::test_architecture_patterns_validation FAILED [ 87%]\ntests/test_architect_agent.py::TestArchitectAgent::test_error_handling FAILED [100%]\n\n=================================== FAILURES ===================================\n___________ TestArchitectAgent.test_design_system_architecture_basic ___________\ntests/test_architect_agent.py:142: in test_design_system_architecture_basic\n    assert \"architecture_patterns\" in result\nE   AssertionError: assert 'architecture_patterns' in {'complexity_analysis': 'complex', 'components': [{'name': 'Frontend Application', 'responsibility': 'User interface and client-side logic', 'technology': 'React.js'}, {'name': 'Backend API', 'responsibility': 'Business logic and data processing', 'technology': 'Node.js'}, {'name': 'Database', 'responsibility': 'Data storage and retrieval', 'technology': 'PostgreSQL'}], 'created_at': '2025-08-16T17:06:54.984532', 'created_by': 'architect_agent', ...}\n----------------------------- Captured stdout call -----------------------------\nLLM Response received: 1610 characters\nCleaned content preview: {\"components\": [{\"name\": \"User Authentication Service\", \"type\": \"microservice\", \"description\": \"Handles user registration, login, and authentication\", \"technologies\": [\"Node.js\", \"JWT\", \"bcrypt\"], \"re...\nLLM call failed: Invalid LLM response format - missing technology_stack\nLLM error type: ValueError\n_____________ TestArchitectAgent.test_architecture_component_types _____________\ntests/test_architect_agent.py:191: in test_architecture_component_types\n    assert component[\"type\"] in valid_types\n           ^^^^^^^^^^^^^^^^^\nE   KeyError: 'type'\n----------------------------- Captured stdout call -----------------------------\nLLM Response received: 686 characters\nCleaned content preview: {\"components\": [{\"name\": \"API Gateway\", \"type\": \"gateway\", \"description\": \"test\", \"technologies\": [], \"responsibilities\": [], \"interfaces\": [], \"data_stores\": []}, {\"name\": \"User Service\", \"type\": \"mi...\nLLM call failed: Invalid LLM response format - missing technology_stack\nLLM error type: ValueError\n_____________ TestArchitectAgent.test_technology_stack_consistency _____________\ntests/test_architect_agent.py:234: in test_technology_stack_consistency\n    for tech in component[\"technologies\"]:\n                ^^^^^^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'technologies'\n----------------------------- Captured stdout call -----------------------------\nLLM Response received: 395 characters\nCleaned content preview: {\"components\": [{\"name\": \"Backend API\", \"type\": \"microservice\", \"description\": \"Main API service\", \"technologies\": [\"Python\", \"FastAPI\", \"PostgreSQL\"], \"responsibilities\": [\"API endpoints\"], \"interfac...\nLLM call failed: Invalid LLM response format - missing technology_stack\nLLM error type: ValueError\n___________ TestArchitectAgent.test_security_considerations_coverage ___________\ntests/test_architect_agent.py:264: in test_security_considerations_coverage\n    security_text = \" \".join(result[\"security_considerations\"]).lower()\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'security_considerations'\n----------------------------- Captured stdout call -----------------------------\nLLM Response received: 314 characters\nCleaned content preview: {\"components\": [], \"architecture_patterns\": [], \"data_flow\": [], \"security_considerations\": [\"Authentication and authorization\", \"Data encryption in transit and at rest\", \"Input validation and sanitiz...\nLLM call failed: Invalid LLM response format - missing technology_stack\nLLM error type: ValueError\n________________ TestArchitectAgent.test_data_flow_completeness ________________\ntests/test_architect_agent.py:309: in test_data_flow_completeness\n    data_flows = result[\"data_flow\"]\n                 ^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'data_flow'\n----------------------------- Captured stdout call -----------------------------\nLLM Response received: 564 characters\nCleaned content preview: {\"components\": [{\"name\": \"Frontend\", \"type\": \"web_app\", \"description\": \"test\", \"technologies\": [], \"responsibilities\": [], \"interfaces\": [], \"data_stores\": []}, {\"name\": \"Backend\", \"type\": \"microservi...\nLLM call failed: Invalid LLM response format - missing technology_stack\nLLM error type: ValueError\n___________ TestArchitectAgent.test_architecture_patterns_validation ___________\ntests/test_architect_agent.py:377: in test_architecture_patterns_validation\n    patterns = result[\"architecture_patterns\"]\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'architecture_patterns'\n----------------------------- Captured stdout call -----------------------------\nLLM Response received: 286 characters\nCleaned content preview: {\"components\": [], \"architecture_patterns\": [{\"pattern\": \"Microservices\", \"rationale\": \"Enables independent scaling and deployment\"}, {\"pattern\": \"Event-Driven Architecture\", \"rationale\": \"Supports re...\nLLM call failed: Invalid LLM response format - missing technology_stack\nLLM error type: ValueError\n____________________ TestArchitectAgent.test_error_handling ____________________\ntests/test_architect_agent.py:408: in test_error_handling\n    assert \"error\" in result\nE   AssertionError: assert 'error' in {'complexity_analysis': 'complex', 'components': [{'name': 'Frontend Application', 'responsibility': 'User interface and client-side logic', 'technology': 'React.js'}, {'name': 'Backend API', 'responsibility': 'Business logic and data processing', 'technology': 'Node.js'}, {'name': 'Database', 'responsibility': 'Data storage and retrieval', 'technology': 'PostgreSQL'}], 'created_at': '2025-08-16T17:06:55.107026', 'created_by': 'architect_agent', ...}\n----------------------------- Captured stdout call -----------------------------\nLLM call failed: API Error\nLLM error type: Exception\nAPI key issue detected - check OPENAI_API_KEY environment variable\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_architect_agent.json\n=========================== short test summary info ============================\nFAILED tests/test_architect_agent.py::TestArchitectAgent::test_design_system_architecture_basic\nFAILED tests/test_architect_agent.py::TestArchitectAgent::test_architecture_component_types\nFAILED tests/test_architect_agent.py::TestArchitectAgent::test_technology_stack_consistency\nFAILED tests/test_architect_agent.py::TestArchitectAgent::test_security_considerations_coverage\nFAILED tests/test_architect_agent.py::TestArchitectAgent::test_data_flow_completeness\nFAILED tests/test_architect_agent.py::TestArchitectAgent::test_architecture_patterns_validation\nFAILED tests/test_architect_agent.py::TestArchitectAgent::test_error_handling\n========================= 7 failed, 1 passed in 0.99s ==========================\n",
        "stderr": "",
        "return_code": 1
      },
      "Developer Agent": {
        "status": "FAILED",
        "execution_time": 2.165468215942383,
        "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.4.1, pluggy-1.6.0 -- /workspaces/agentic-ecosystem/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.3', 'Platform': 'Linux-6.8.0-1030-azure-x86_64-with-glibc2.39', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'httpx': '0.35.0', 'asyncio': '1.1.0', 'anyio': '4.10.0', 'langsmith': '0.4.14', 'metadata': '3.1.1', 'json-report': '1.5.0', 'mock': '3.14.1'}, 'JAVA_HOME': '/usr/local/sdkman/candidates/java/current'}\nrootdir: /workspaces/agentic-ecosystem\nconfigfile: pytest.ini\nplugins: httpx-0.35.0, asyncio-1.1.0, anyio-4.10.0, langsmith-0.4.14, metadata-3.1.1, json-report-1.5.0, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 8 items\n\ntests/test_developer_agent.py::TestDeveloperAgent::test_generate_implementation_plan_basic PASSED [ 12%]\ntests/test_developer_agent.py::TestDeveloperAgent::test_task_dependency_validation PASSED [ 25%]\ntests/test_developer_agent.py::TestDeveloperAgent::test_technical_specifications_completeness PASSED [ 37%]\ntests/test_developer_agent.py::TestDeveloperAgent::test_effort_estimation_reasonableness PASSED [ 50%]\ntests/test_developer_agent.py::TestDeveloperAgent::test_deployment_strategy_coverage PASSED [ 62%]\ntests/test_developer_agent.py::TestDeveloperAgent::test_risk_mitigation_priorities PASSED [ 75%]\ntests/test_developer_agent.py::TestDeveloperAgent::test_implementation_file_output PASSED [ 87%]\ntests/test_developer_agent.py::TestDeveloperAgent::test_error_handling FAILED [100%]\n\n=================================== FAILURES ===================================\n____________________ TestDeveloperAgent.test_error_handling ____________________\ntests/test_developer_agent.py:481: in test_error_handling\n    assert \"error\" in result\nE   AssertionError: assert 'error' in {'created_at': '2025-08-16T17:06:57.179304', 'created_by': 'developer_agent', 'estimated_timeline': '2-3 weeks', 'implementation_phases': [{'deliverables': ['Working React environment', 'Build configuration'], 'description': 'Initialize React project and dependencies', 'duration': '1-2 days', 'phase': 'Phase 1: Project Setup', ...}, {'deliverables': ['React components', 'Application logic', 'Styling'], 'description': 'Build React components and logic', 'duration': '1-2 weeks', 'phase': 'Phase 2: Component Development', ...}, {'deliverables': ['Test suite', 'Production build', 'Deployment'], 'description': 'Test components and deploy application', 'duration': '3-5 days', 'phase': 'Phase 3: Testing & Deployment', ...}], ...}\n----------------------------- Captured stdout call -----------------------------\nLLM implementation planning failed: API Error\n\u2705 Generated React app for complexity: medium, frontend: \n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-dev-project-123/package.json\nError saving source file src/App.js: [Errno 2] No such file or directory: '/workspaces/agentic-ecosystem/out/project_test-dev-project-123/src/src/App.js'\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-dev-project-123/docs/README.md\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-dev-project-123/docs/README.md\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_developer_agent.json\n=========================== short test summary info ============================\nFAILED tests/test_developer_agent.py::TestDeveloperAgent::test_error_handling\n========================= 1 failed, 7 passed in 1.16s ==========================\n",
        "stderr": "",
        "return_code": 1
      },
      "Tester Agent": {
        "status": "FAILED",
        "execution_time": 1.9253382682800293,
        "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.4.1, pluggy-1.6.0 -- /workspaces/agentic-ecosystem/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.3', 'Platform': 'Linux-6.8.0-1030-azure-x86_64-with-glibc2.39', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'httpx': '0.35.0', 'asyncio': '1.1.0', 'anyio': '4.10.0', 'langsmith': '0.4.14', 'metadata': '3.1.1', 'json-report': '1.5.0', 'mock': '3.14.1'}, 'JAVA_HOME': '/usr/local/sdkman/candidates/java/current'}\nrootdir: /workspaces/agentic-ecosystem\nconfigfile: pytest.ini\nplugins: httpx-0.35.0, asyncio-1.1.0, anyio-4.10.0, langsmith-0.4.14, metadata-3.1.1, json-report-1.5.0, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 9 items\n\ntests/test_tester_agent.py::TestTesterAgent::test_create_test_strategy_basic FAILED [ 11%]\ntests/test_tester_agent.py::TestTesterAgent::test_test_case_completeness FAILED [ 22%]\ntests/test_tester_agent.py::TestTesterAgent::test_test_priorities_distribution FAILED [ 33%]\ntests/test_tester_agent.py::TestTesterAgent::test_test_coverage_areas FAILED [ 44%]\ntests/test_tester_agent.py::TestTesterAgent::test_automation_framework_selection FAILED [ 55%]\ntests/test_tester_agent.py::TestTesterAgent::test_test_strategy_comprehensiveness FAILED [ 66%]\ntests/test_tester_agent.py::TestTesterAgent::test_test_data_appropriateness FAILED [ 77%]\ntests/test_tester_agent.py::TestTesterAgent::test_test_strategy_file_output PASSED [ 88%]\ntests/test_tester_agent.py::TestTesterAgent::test_error_handling FAILED  [100%]\n\n=================================== FAILURES ===================================\n_______________ TestTesterAgent.test_create_test_strategy_basic ________________\ntests/test_tester_agent.py:170: in test_create_test_strategy_basic\n    assert \"test_cases\" in result\nE   AssertionError: assert 'test_cases' in {'automation_strategy': {'automation_percentage': '80%', 'ci_cd_integration': 'GitHub Actions workflow', 'framework_recommendation': 'Cypress for E2E testing', 'tools': ['Cypress', 'Jest', 'HTML Validator']}, 'created_at': '2025-08-16T17:06:59.040377', 'created_by': 'tester_agent', 'project_id': 'test-tester-project-123', ...}\n----------------------------- Captured stdout call -----------------------------\nTest strategy LLM response: 2298 characters\nLLM test strategy generation failed: Invalid test strategy format\n_________________ TestTesterAgent.test_test_case_completeness __________________\ntests/test_tester_agent.py:247: in test_test_case_completeness\n    test_cases = result[\"test_cases\"]\n                 ^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'test_cases'\n----------------------------- Captured stdout call -----------------------------\nTest strategy LLM response: 1052 characters\nLLM test strategy generation failed: Invalid test strategy format\n______________ TestTesterAgent.test_test_priorities_distribution _______________\ntests/test_tester_agent.py:284: in test_test_priorities_distribution\n    test_cases = result[\"test_cases\"]\n                 ^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'test_cases'\n----------------------------- Captured stdout call -----------------------------\nTest strategy LLM response: 893 characters\nLLM test strategy generation failed: Invalid test strategy format\n___________________ TestTesterAgent.test_test_coverage_areas ___________________\ntests/test_tester_agent.py:342: in test_test_coverage_areas\n    coverage = result[\"test_coverage\"]\n               ^^^^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'test_coverage'\n----------------------------- Captured stdout call -----------------------------\nTest strategy LLM response: 561 characters\nLLM test strategy generation failed: Invalid test strategy format\n_____________ TestTesterAgent.test_automation_framework_selection ______________\ntests/test_tester_agent.py:384: in test_automation_framework_selection\n    automation = result[\"automation_framework\"]\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'automation_framework'\n----------------------------- Captured stdout call -----------------------------\nTest strategy LLM response: 370 characters\nLLM test strategy generation failed: Invalid test strategy format\n_____________ TestTesterAgent.test_test_strategy_comprehensiveness _____________\ntests/test_tester_agent.py:433: in test_test_strategy_comprehensiveness\n    strategy = result[\"test_strategy\"]\n               ^^^^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'test_strategy'\n----------------------------- Captured stdout call -----------------------------\nTest strategy LLM response: 679 characters\nLLM test strategy generation failed: Invalid test strategy format\n________________ TestTesterAgent.test_test_data_appropriateness ________________\ntests/test_tester_agent.py:505: in test_test_data_appropriateness\n    test_cases = result[\"test_cases\"]\n                 ^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'test_cases'\n----------------------------- Captured stdout call -----------------------------\nTest strategy LLM response: 765 characters\nLLM test strategy generation failed: Invalid test strategy format\n_____________________ TestTesterAgent.test_error_handling ______________________\ntests/test_tester_agent.py:558: in test_error_handling\n    assert \"error\" in result\nE   AssertionError: assert 'error' in {'automation_strategy': {'automation_percentage': '80%', 'ci_cd_integration': 'GitHub Actions workflow', 'framework_recommendation': 'Cypress for E2E testing', 'tools': ['Cypress', 'Jest', 'HTML Validator']}, 'created_at': '2025-08-16T17:06:59.187772', 'created_by': 'tester_agent', 'project_id': 'test-tester-project-123', ...}\n----------------------------- Captured stdout call -----------------------------\nLLM test strategy generation failed: API Error\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_tester_agent.json\n=========================== short test summary info ============================\nFAILED tests/test_tester_agent.py::TestTesterAgent::test_create_test_strategy_basic\nFAILED tests/test_tester_agent.py::TestTesterAgent::test_test_case_completeness\nFAILED tests/test_tester_agent.py::TestTesterAgent::test_test_priorities_distribution\nFAILED tests/test_tester_agent.py::TestTesterAgent::test_test_coverage_areas\nFAILED tests/test_tester_agent.py::TestTesterAgent::test_automation_framework_selection\nFAILED tests/test_tester_agent.py::TestTesterAgent::test_test_strategy_comprehensiveness\nFAILED tests/test_tester_agent.py::TestTesterAgent::test_test_data_appropriateness\nFAILED tests/test_tester_agent.py::TestTesterAgent::test_error_handling - Ass...\n========================= 8 failed, 1 passed in 1.02s ==========================\n",
        "stderr": "",
        "return_code": 1
      },
      "LangGraph Workflow": {
        "status": "FAILED",
        "execution_time": 437.3060646057129,
        "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.4.1, pluggy-1.6.0 -- /workspaces/agentic-ecosystem/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.3', 'Platform': 'Linux-6.8.0-1030-azure-x86_64-with-glibc2.39', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'httpx': '0.35.0', 'asyncio': '1.1.0', 'anyio': '4.10.0', 'langsmith': '0.4.14', 'metadata': '3.1.1', 'json-report': '1.5.0', 'mock': '3.14.1'}, 'JAVA_HOME': '/usr/local/sdkman/candidates/java/current'}\nrootdir: /workspaces/agentic-ecosystem\nconfigfile: pytest.ini\nplugins: httpx-0.35.0, asyncio-1.1.0, anyio-4.10.0, langsmith-0.4.14, metadata-3.1.1, json-report-1.5.0, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 11 items\n\ntests/test_workflow.py::TestLangGraphWorkflow::test_workflow_initialization PASSED [  9%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_project_state_structure PASSED [ 18%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_workflow_execution_success FAILED [ 27%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_workflow_error_handling FAILED [ 36%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_workflow_partial_completion FAILED [ 45%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_workflow_state_transitions PASSED [ 54%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_summary_report_generation FAILED [ 63%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_workflow_message_tracking FAILED [ 72%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_workflow_with_callback PASSED [ 81%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_workflow_output_files PASSED [ 90%]\ntests/test_workflow.py::TestLangGraphWorkflow::test_workflow_performance FAILED [100%]\n\n=================================== FAILURES ===================================\n____________ TestLangGraphWorkflow.test_workflow_execution_success _____________\n/usr/lib/python3.12/unittest/mock.py:923: in assert_called_once\n    raise AssertionError(msg)\nE   AssertionError: Expected 'invoke' to have been called once. Called 0 times.\n\nDuring handling of the above exception, another exception occurred:\ntests/test_workflow.py:136: in test_workflow_execution_success\n    mock_business_analysis.invoke.assert_called_once()\nE   AssertionError: Expected 'invoke' to have been called once. Called 0 times.\n----------------------------- Captured stdout call -----------------------------\n\ud83d\ude80 Starting software development workflow for project: test-workflow-project-123\n\ud83d\udcdd Specification: \n        Create a simple todo application with the following features:\n        - Add new todos\n     ...\n\ud83d\udd0d Starting Business Analysis for project test-workflow-project-123\nJSON parsing failed, using fallback\n\u2705 Business Analysis completed with 3 user stories\n\ud83c\udfd7\ufe0f Starting Architecture Design for project test-workflow-project-123\nLLM Response received: 2531 characters\nCleaned content preview: {\n    \"complexity_analysis\": \"simple\",\n    \"top_3_options\": [\n        {\n            \"option\": 1,\n            \"technology\": \"HTML/CSS/JavaScript\",\n            \"pros\": [\"Lightweight and fast\", \"No addit...\nLLM analysis successful: simple complexity\n\u2705 Architecture Design completed with 4 components\n\ud83d\udcbb Starting Implementation Planning for project test-workflow-project-123\nImplementation plan LLM response: 3068 characters\nLLM implementation plan generated successfully\nCode generation LLM response: 4641 characters\n\u2705 LLM generated project-specific code successfully\n\u2705 Generated simple web app for complexity: simple, frontend: HTML/CSS/JavaScript\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/index.html\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/styles.css\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/script.js\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Implementation Planning completed with 3 phases\n\ud83e\uddea Starting Test Strategy Creation for project test-workflow-project-123\nTest strategy LLM response: 4791 characters\nLLM test strategy generated successfully\n\u2705 Test Strategy completed with 0 test cases\n\ud83c\udf89 Completing project test-workflow-project-123\n\u2705 Project test-workflow-project-123 completed!\n\ud83c\udfaf Workflow completed for project test-workflow-project-123\n______________ TestLangGraphWorkflow.test_workflow_error_handling ______________\ntests/test_workflow.py:156: in test_workflow_error_handling\n    assert len(result[\"errors\"]) > 0\nE   assert 0 > 0\nE    +  where 0 = len([])\n----------------------------- Captured stdout call -----------------------------\n\ud83d\ude80 Starting software development workflow for project: test-workflow-project-123\n\ud83d\udcdd Specification: \n        Create a simple todo application with the following features:\n        - Add new todos\n     ...\n\ud83d\udd0d Starting Business Analysis for project test-workflow-project-123\nJSON parsing failed, using fallback\n\u2705 Business Analysis completed with 3 user stories\n\ud83c\udfd7\ufe0f Starting Architecture Design for project test-workflow-project-123\nLLM Response received: 2333 characters\nCleaned content preview: {\n    \"complexity_analysis\": \"simple\",\n    \"top_3_options\": [\n        {\n            \"option\": 1,\n            \"technology\": \"HTML/CSS/JavaScript\",\n            \"pros\": [\"Lightweight and fast\", \"No addit...\nLLM analysis successful: simple complexity\n\u2705 Architecture Design completed with 3 components\n\ud83d\udcbb Starting Implementation Planning for project test-workflow-project-123\nImplementation plan LLM response: 3527 characters\nLLM implementation plan generated successfully\nCode generation LLM response: 4445 characters\n\u2705 LLM generated project-specific code successfully\n\u2705 Generated simple web app for complexity: simple, frontend: HTML/CSS/JavaScript\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/index.html\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/styles.css\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/script.js\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Implementation Planning completed with 3 phases\n\ud83e\uddea Starting Test Strategy Creation for project test-workflow-project-123\nTest strategy LLM response: 5923 characters\nLLM test strategy generated successfully\n\u2705 Test Strategy completed with 0 test cases\n\ud83c\udf89 Completing project test-workflow-project-123\n\u2705 Project test-workflow-project-123 completed!\n\ud83c\udfaf Workflow completed for project test-workflow-project-123\n____________ TestLangGraphWorkflow.test_workflow_partial_completion ____________\ntests/test_workflow.py:183: in test_workflow_partial_completion\n    assert result[\"system_architecture\"] is None    # Second phase failed\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AssertionError: assert {'complexity_analysis': 'simple', 'components': [{'name': 'Todo List', 'responsibility': 'Displays the list of todos and allows user interaction', 'technology': 'HTML/CSS/JavaScript'}, {'name': 'Todo Input', 'responsibility': 'Handles user input for adding new todos', 'technology': 'HTML/CSS/JavaScript'}, {'name': 'Todo Filters', 'responsibility': 'Allows users to filter todos by status (all, completed, active)', 'technology': 'HTML/CSS/JavaScript'}], 'created_at': '2025-08-16T17:09:20.251474', 'created_by': 'architect_agent', ...} is None\n----------------------------- Captured stdout call -----------------------------\n\ud83d\ude80 Starting software development workflow for project: test-workflow-project-123\n\ud83d\udcdd Specification: \n        Create a simple todo application with the following features:\n        - Add new todos\n     ...\n\ud83d\udd0d Starting Business Analysis for project test-workflow-project-123\nJSON parsing failed, using fallback\n\u2705 Business Analysis completed with 3 user stories\n\ud83c\udfd7\ufe0f Starting Architecture Design for project test-workflow-project-123\nLLM Response received: 2378 characters\nCleaned content preview: {\n    \"complexity_analysis\": \"simple\",\n    \"top_3_options\": [\n        {\n            \"option\": 1,\n            \"technology\": \"HTML/CSS/JavaScript\",\n            \"pros\": [\"Lightweight and fast\", \"No addit...\nLLM analysis successful: simple complexity\n\u2705 Architecture Design completed with 3 components\n\ud83d\udcbb Starting Implementation Planning for project test-workflow-project-123\nImplementation plan LLM response: 3594 characters\nLLM implementation plan generated successfully\nCode generation LLM response: 5071 characters\n\u2705 LLM generated project-specific code successfully\n\u2705 Generated simple web app for complexity: simple, frontend: HTML/CSS/JavaScript\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/index.html\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/styles.css\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/script.js\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Implementation Planning completed with 3 phases\n\ud83e\uddea Starting Test Strategy Creation for project test-workflow-project-123\nTest strategy LLM response: 5557 characters\nLLM test strategy generated successfully\n\u2705 Test Strategy completed with 0 test cases\n\ud83c\udf89 Completing project test-workflow-project-123\n\u2705 Project test-workflow-project-123 completed!\n\ud83c\udfaf Workflow completed for project test-workflow-project-123\n_____________ TestLangGraphWorkflow.test_summary_report_generation _____________\n/usr/lib/python3.12/unittest/mock.py:913: in assert_called\n    raise AssertionError(msg)\nE   AssertionError: Expected 'mkdir' to have been called.\n\nDuring handling of the above exception, another exception occurred:\ntests/test_workflow.py:235: in test_summary_report_generation\n    mock_dir.mkdir.assert_called()\nE   AssertionError: Expected 'mkdir' to have been called.\n----------------------------- Captured stdout call -----------------------------\n{\n  \"project_id\": \"test-workflow-project-123\",\n  \"specification\": \"\\n        Create a simple todo application with the following features:\\n        - Add new todos\\n        - Mark todos as complete\\n        - Delete todos\\n        - Filter todos by status\\n        \",\n  \"status\": \"completed\",\n  \"completed_at\": \"2025-08-16T17:10:07.257406\",\n  \"phases_completed\": \"completed\",\n  \"artifacts_generated\": {\n    \"business_analysis\": true,\n    \"system_architecture\": true,\n    \"implementation_plan\": true,\n    \"test_strategy\": true\n  },\n  \"errors\": [],\n  \"summary\": {\n    \"user_stories_count\": 1,\n    \"components_count\": 1,\n    \"implementation_phases\": 1,\n    \"test_cases_count\": 1\n  }\n}Error generating summary report: [Errno 9] Bad file descriptor\n_____________ TestLangGraphWorkflow.test_workflow_message_tracking _____________\ntests/test_workflow.py:258: in test_workflow_message_tracking\n    assert \"role\" in message\nE   AssertionError: assert 'role' in SystemMessage(content='Starting software development workflow', additional_kwargs={'timestamp': '2025-08-16T17:07:01.446089'}, response_metadata={}, id='d9fa87b4-29f9-4ce0-a77c-c493b2cd2424')\n----------------------------- Captured stdout call -----------------------------\n\ud83d\ude80 Starting software development workflow for project: test-workflow-project-123\n\ud83d\udcdd Specification: \n        Create a simple todo application with the following features:\n        - Add new todos\n     ...\n\ud83d\udd0d Starting Business Analysis for project test-workflow-project-123\nJSON parsing failed, using fallback\n\u2705 Business Analysis completed with 3 user stories\n\ud83c\udfd7\ufe0f Starting Architecture Design for project test-workflow-project-123\nLLM Response received: 2420 characters\nCleaned content preview: {\n    \"complexity_analysis\": \"simple\",\n    \"top_3_options\": [\n        {\n            \"option\": 1,\n            \"technology\": \"HTML/CSS/JavaScript\",\n            \"pros\": [\"Lightweight and fast\", \"No addit...\nLLM analysis successful: simple complexity\n\u2705 Architecture Design completed with 3 components\n\ud83d\udcbb Starting Implementation Planning for project test-workflow-project-123\nImplementation plan LLM response: 3452 characters\nLLM implementation plan generated successfully\nCode generation LLM response: 4942 characters\n\u2705 LLM generated project-specific code successfully\n\u2705 Generated simple web app for complexity: simple, frontend: HTML/CSS/JavaScript\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/index.html\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/styles.css\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/script.js\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Implementation Planning completed with 3 phases\n\ud83e\uddea Starting Test Strategy Creation for project test-workflow-project-123\nTest strategy LLM response: 5011 characters\nLLM test strategy generated successfully\n\u2705 Test Strategy completed with 0 test cases\n\ud83c\udf89 Completing project test-workflow-project-123\n\u2705 Project test-workflow-project-123 completed!\n\ud83c\udfaf Workflow completed for project test-workflow-project-123\n_______________ TestLangGraphWorkflow.test_workflow_performance ________________\ntests/test_workflow.py:334: in test_workflow_performance\n    assert execution_time < 5.0, f\"Workflow took too long: {execution_time}s\"\nE   AssertionError: Workflow took too long: 58.99978566169739s\nE   assert 58.99978566169739 < 5.0\n----------------------------- Captured stdout call -----------------------------\n\ud83d\ude80 Starting software development workflow for project: test-workflow-project-123\n\ud83d\udcdd Specification: \n        Create a simple todo application with the following features:\n        - Add new todos\n     ...\n\ud83d\udd0d Starting Business Analysis for project test-workflow-project-123\nJSON parsing failed, using fallback\n\u2705 Business Analysis completed with 3 user stories\n\ud83c\udfd7\ufe0f Starting Architecture Design for project test-workflow-project-123\nLLM Response received: 2562 characters\nCleaned content preview: {\n    \"complexity_analysis\": \"simple\",\n    \"top_3_options\": [\n        {\n            \"option\": 1,\n            \"technology\": \"HTML/CSS/JavaScript\",\n            \"pros\": [\"Lightweight and fast\", \"No addit...\nLLM analysis successful: simple complexity\n\u2705 Architecture Design completed with 4 components\n\ud83d\udcbb Starting Implementation Planning for project test-workflow-project-123\nImplementation plan LLM response: 3488 characters\nLLM implementation plan generated successfully\nCode generation LLM response: 4738 characters\n\u2705 LLM generated project-specific code successfully\n\u2705 Generated simple web app for complexity: simple, frontend: HTML/CSS/JavaScript\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/index.html\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/styles.css\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/src/script.js\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Saved source file: /workspaces/agentic-ecosystem/out/project_test-workflow-project-123/docs/README.md\n\u2705 Implementation Planning completed with 3 phases\n\ud83e\uddea Starting Test Strategy Creation for project test-workflow-project-123\nTest strategy LLM response: 5596 characters\nLLM test strategy generated successfully\n\u2705 Test Strategy completed with 0 test cases\n\ud83c\udf89 Completing project test-workflow-project-123\n\u2705 Project test-workflow-project-123 completed!\n\ud83c\udfaf Workflow completed for project test-workflow-project-123\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_langgraph_workflow.json\n=========================== short test summary info ============================\nFAILED tests/test_workflow.py::TestLangGraphWorkflow::test_workflow_execution_success\nFAILED tests/test_workflow.py::TestLangGraphWorkflow::test_workflow_error_handling\nFAILED tests/test_workflow.py::TestLangGraphWorkflow::test_workflow_partial_completion\nFAILED tests/test_workflow.py::TestLangGraphWorkflow::test_summary_report_generation\nFAILED tests/test_workflow.py::TestLangGraphWorkflow::test_workflow_message_tracking\nFAILED tests/test_workflow.py::TestLangGraphWorkflow::test_workflow_performance\n=================== 6 failed, 5 passed in 436.31s (0:07:16) ====================\n",
        "stderr": "",
        "return_code": 1
      },
      "MCP Server": {
        "status": "FAILED",
        "execution_time": 2.815195083618164,
        "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.4.1, pluggy-1.6.0 -- /workspaces/agentic-ecosystem/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.3', 'Platform': 'Linux-6.8.0-1030-azure-x86_64-with-glibc2.39', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'httpx': '0.35.0', 'asyncio': '1.1.0', 'anyio': '4.10.0', 'langsmith': '0.4.14', 'metadata': '3.1.1', 'json-report': '1.5.0', 'mock': '3.14.1'}, 'JAVA_HOME': '/usr/local/sdkman/candidates/java/current'}\nrootdir: /workspaces/agentic-ecosystem\nconfigfile: pytest.ini\nplugins: httpx-0.35.0, asyncio-1.1.0, anyio-4.10.0, langsmith-0.4.14, metadata-3.1.1, json-report-1.5.0, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 16 items\n\ntests/test_mcp_server.py::TestMCPServer::test_project_manager_initialization PASSED [  6%]\ntests/test_mcp_server.py::TestMCPServer::test_project_manager_create_project FAILED [ 12%]\ntests/test_mcp_server.py::TestMCPServer::test_project_manager_persistence FAILED [ 18%]\ntests/test_mcp_server.py::TestMCPServer::test_project_manager_update_project FAILED [ 25%]\ntests/test_mcp_server.py::TestMCPServer::test_project_manager_list_projects FAILED [ 31%]\ntests/test_mcp_server.py::TestMCPServer::test_handle_create_project_enhanced PASSED [ 37%]\ntests/test_mcp_server.py::TestMCPServer::test_handle_get_project_status_enhanced PASSED [ 43%]\ntests/test_mcp_server.py::TestMCPServer::test_handle_get_project_status_not_found PASSED [ 50%]\ntests/test_mcp_server.py::TestMCPServer::test_handle_list_projects_enhanced PASSED [ 56%]\ntests/test_mcp_server.py::TestMCPServer::test_handle_monitor_project_progress PASSED [ 62%]\ntests/test_mcp_server.py::TestMCPServer::test_handle_get_project_artifacts_enhanced PASSED [ 68%]\ntests/test_mcp_server.py::TestMCPServer::test_handle_get_project_artifacts_not_found PASSED [ 75%]\ntests/test_mcp_server.py::TestMCPServer::test_error_handling_in_handlers FAILED [ 81%]\ntests/test_mcp_server.py::TestMCPServer::test_project_filtering PASSED   [ 87%]\ntests/test_mcp_server.py::TestMCPServer::test_progress_calculation PASSED [ 93%]\ntests/test_mcp_server.py::TestMCPServer::test_project_validation PASSED  [100%]\n\n=================================== FAILURES ===================================\n______________ TestMCPServer.test_project_manager_create_project _______________\ntests/test_mcp_server.py:76: in test_project_manager_create_project\n    project_id = pm.create_project(\nE   TypeError: ProjectManager.create_project() missing 1 required positional argument: 'project_id'\n________________ TestMCPServer.test_project_manager_persistence ________________\ntests/test_mcp_server.py:96: in test_project_manager_persistence\n    project_id = pm.create_project(\nE   TypeError: ProjectManager.create_project() missing 1 required positional argument: 'project_id'\n______________ TestMCPServer.test_project_manager_update_project _______________\ntests/test_mcp_server.py:113: in test_project_manager_update_project\n    project_id = pm.create_project(specification=self.sample_specification)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: ProjectManager.create_project() missing 2 required positional arguments: 'project_id' and 'title'\n_______________ TestMCPServer.test_project_manager_list_projects _______________\ntests/test_mcp_server.py:131: in test_project_manager_list_projects\n    project1 = pm.create_project(specification=\"Project 1\", title=\"First Project\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: ProjectManager.create_project() missing 1 required positional argument: 'project_id'\n________________ TestMCPServer.test_error_handling_in_handlers _________________\ntests/test_mcp_server.py:344: in test_error_handling_in_handlers\n    result = await handle_create_project_enhanced(arguments)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsrc/langgraph_agents/enhanced_mcp_server.py:397: in handle_create_project_enhanced\n    specification = arguments[\"specification\"]\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   KeyError: 'specification'\n=============================== warnings summary ===============================\ntests/test_mcp_server.py::TestMCPServer::test_handle_get_project_status_enhanced\n  /usr/lib/python3.12/unittest/mock.py:2188: RuntimeWarning: coroutine 'run_project_workflow_enhanced' was never awaited\n    def __init__(self, name, parent):\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_mcp_server.json\n=========================== short test summary info ============================\nFAILED tests/test_mcp_server.py::TestMCPServer::test_project_manager_create_project\nFAILED tests/test_mcp_server.py::TestMCPServer::test_project_manager_persistence\nFAILED tests/test_mcp_server.py::TestMCPServer::test_project_manager_update_project\nFAILED tests/test_mcp_server.py::TestMCPServer::test_project_manager_list_projects\nFAILED tests/test_mcp_server.py::TestMCPServer::test_error_handling_in_handlers\n=================== 5 failed, 11 passed, 1 warning in 1.76s ====================\n",
        "stderr": "",
        "return_code": 1
      }
    }
  }
}